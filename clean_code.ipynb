{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b7461a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9c9b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Importing required libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport keras_tuner as kt\\nfrom tensorflow import keras\\n\\n# Importing specific modules from libraries\\nfrom keras_tuner.tuners import RandomSearch\\nfrom keras_tuner.engine.hyperparameters import HyperParameters\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Setting numpy print options to display floating point numbers up to 3 decimal points\\nnp.set_printoptions(precision=3, suppress=True)\";\n",
       "                var nbb_formatted_code = \"# Importing required libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport keras_tuner as kt\\nfrom tensorflow import keras\\n\\n# Importing specific modules from libraries\\nfrom keras_tuner.tuners import RandomSearch\\nfrom keras_tuner.engine.hyperparameters import HyperParameters\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Setting numpy print options to display floating point numbers up to 3 decimal points\\nnp.set_printoptions(precision=3, suppress=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "\n",
    "# Importing specific modules from libraries\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Setting numpy print options to display floating point numbers up to 3 decimal points\n",
    "np.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5e0cf",
   "metadata": {},
   "source": [
    "### 1. Load the datasets\n",
    "\n",
    "##### leakage dataset train [m].csv\n",
    "##### leakage dataset validation 1000.csv\n",
    "\n",
    "and store the data as NumPy-Arrays\n",
    "X train, Y train\n",
    "X validation, Y validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d3bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Loading the data from CSV files\\n\\n# Reading the first dataset from a CSV file named \\\"leakage_dataset_train_100.csv\\\" and storing it in a pandas dataframe named df_100\\ndf_100 = pd.read_csv(\\\"Data/leakage_dataset_train_100.csv\\\", header=0)\\n\\n# Reading the second dataset from a CSV file named \\\"leakage_dataset_train_1000.csv\\\" and storing it in a pandas dataframe named df_1000\\ndf_1000 = pd.read_csv(\\\"Data/leakage_dataset_train_1000.csv\\\", header=0)\\n\\n# Reading the validation dataset from a CSV file named \\\"leakage_dataset_validation_1000.csv\\\" and storing it in a pandas dataframe named df_val\\ndf_val = pd.read_csv(\\\"Data/leakage_dataset_validation_1000.csv\\\", header=0)\";\n",
       "                var nbb_formatted_code = \"# Loading the data from CSV files\\n\\n# Reading the first dataset from a CSV file named \\\"leakage_dataset_train_100.csv\\\" and storing it in a pandas dataframe named df_100\\ndf_100 = pd.read_csv(\\\"Data/leakage_dataset_train_100.csv\\\", header=0)\\n\\n# Reading the second dataset from a CSV file named \\\"leakage_dataset_train_1000.csv\\\" and storing it in a pandas dataframe named df_1000\\ndf_1000 = pd.read_csv(\\\"Data/leakage_dataset_train_1000.csv\\\", header=0)\\n\\n# Reading the validation dataset from a CSV file named \\\"leakage_dataset_validation_1000.csv\\\" and storing it in a pandas dataframe named df_val\\ndf_val = pd.read_csv(\\\"Data/leakage_dataset_validation_1000.csv\\\", header=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the data from CSV files\n",
    "\n",
    "# Reading the first dataset from a CSV file named \"leakage_dataset_train_100.csv\" and storing it in a pandas dataframe named df_100\n",
    "df_100 = pd.read_csv(\"Data/leakage_dataset_train_100.csv\", header=0)\n",
    "\n",
    "# Reading the second dataset from a CSV file named \"leakage_dataset_train_1000.csv\" and storing it in a pandas dataframe named df_1000\n",
    "df_1000 = pd.read_csv(\"Data/leakage_dataset_train_1000.csv\", header=0)\n",
    "\n",
    "# Reading the validation dataset from a CSV file named \"leakage_dataset_validation_1000.csv\" and storing it in a pandas dataframe named df_val\n",
    "df_val = pd.read_csv(\"Data/leakage_dataset_validation_1000.csv\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823765ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Load the features and label from dataframe and convert it to numpy array\\n\\n# List the columns for the features and label for each dataframe\\nfeature_cols = ['mfc1', 'mfc2', 'mfc3', 'mfc4']\\nlabel_cols = ['y1', 'y2']\\n\\n# Load the 100-row training set and convert the features and label to numpy arrays\\ntrain_100 = df_100[feature_cols + label_cols].to_numpy()\\nX_train_100, y_train_100 = train_100[:, :4], train_100[:, 4:]\\n\\n# Load the 1000-row training set and convert the features and label to numpy arrays\\ntrain_1000 = df_1000[feature_cols + label_cols].to_numpy()\\nX_train_1000, y_train_1000 = train_1000[:, :4], train_1000[:, 4:]\\n\\n# Load the validation set and convert the features and label to numpy arrays\\nval = df_val[feature_cols + label_cols].to_numpy()\\nX_val, y_val = val[:, :4], val[:, 4:]\";\n",
       "                var nbb_formatted_code = \"# Load the features and label from dataframe and convert it to numpy array\\n\\n# List the columns for the features and label for each dataframe\\nfeature_cols = [\\\"mfc1\\\", \\\"mfc2\\\", \\\"mfc3\\\", \\\"mfc4\\\"]\\nlabel_cols = [\\\"y1\\\", \\\"y2\\\"]\\n\\n# Load the 100-row training set and convert the features and label to numpy arrays\\ntrain_100 = df_100[feature_cols + label_cols].to_numpy()\\nX_train_100, y_train_100 = train_100[:, :4], train_100[:, 4:]\\n\\n# Load the 1000-row training set and convert the features and label to numpy arrays\\ntrain_1000 = df_1000[feature_cols + label_cols].to_numpy()\\nX_train_1000, y_train_1000 = train_1000[:, :4], train_1000[:, 4:]\\n\\n# Load the validation set and convert the features and label to numpy arrays\\nval = df_val[feature_cols + label_cols].to_numpy()\\nX_val, y_val = val[:, :4], val[:, 4:]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the features and label from dataframe and convert it to numpy array\n",
    "\n",
    "# List the columns for the features and label for each dataframe\n",
    "feature_cols = ['mfc1', 'mfc2', 'mfc3', 'mfc4']\n",
    "label_cols = ['y1', 'y2']\n",
    "\n",
    "# Load the 100-row training set and convert the features and label to numpy arrays\n",
    "train_100 = df_100[feature_cols + label_cols].to_numpy()\n",
    "X_train_100, y_train_100 = train_100[:, :4], train_100[:, 4:]\n",
    "\n",
    "# Load the 1000-row training set and convert the features and label to numpy arrays\n",
    "train_1000 = df_1000[feature_cols + label_cols].to_numpy()\n",
    "X_train_1000, y_train_1000 = train_1000[:, :4], train_1000[:, 4:]\n",
    "\n",
    "# Load the validation set and convert the features and label to numpy arrays\n",
    "val = df_val[feature_cols + label_cols].to_numpy()\n",
    "X_val, y_val = val[:, :4], val[:, 4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf62ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# # Calculate the mean and standard deviation of x1, x2, and x3 in the training data\\n# x1_mean = np.mean(X_train_1000[:, 0])\\n# x2_mean = np.mean(X_train_1000[:, 1])\\n# x3_mean = np.mean(X_train_1000[:, 2])\\n# x4_mean = np.mean(X_train_1000[:, 3])\\n\\n# x1_std = np.std(X_train_1000[:, 0])\\n# x2_std = np.std(X_train_1000[:, 1])\\n# x3_std = np.std(X_train_1000[:, 2])\\n# x4_std = np.std(X_train_1000[:, 3])\";\n",
       "                var nbb_formatted_code = \"# # Calculate the mean and standard deviation of x1, x2, and x3 in the training data\\n# x1_mean = np.mean(X_train_1000[:, 0])\\n# x2_mean = np.mean(X_train_1000[:, 1])\\n# x3_mean = np.mean(X_train_1000[:, 2])\\n# x4_mean = np.mean(X_train_1000[:, 3])\\n\\n# x1_std = np.std(X_train_1000[:, 0])\\n# x2_std = np.std(X_train_1000[:, 1])\\n# x3_std = np.std(X_train_1000[:, 2])\\n# x4_std = np.std(X_train_1000[:, 3])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Calculate the mean and standard deviation of x1, x2, and x3 in the training data\n",
    "# x1_mean = np.mean(X_train_1000[:, 0])\n",
    "# x2_mean = np.mean(X_train_1000[:, 1])\n",
    "# x3_mean = np.mean(X_train_1000[:, 2])\n",
    "# x4_mean = np.mean(X_train_1000[:, 3])\n",
    "\n",
    "# x1_std = np.std(X_train_1000[:, 0])\n",
    "# x2_std = np.std(X_train_1000[:, 1])\n",
    "# x3_std = np.std(X_train_1000[:, 2])\n",
    "# x4_std = np.std(X_train_1000[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f617d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# # Subtract the mean from x1, x2, and x3 in both the training and validation/test data\\n# X_train_1000[:, 0] = (X_train_1000[:, 0] - x1_mean) / x1_std\\n# X_train_1000[:, 1] = (X_train_1000[:, 1] - x2_mean) / x2_std\\n# X_train_1000[:, 2] = (X_train_1000[:, 2] - x3_mean) / x3_std\\n# X_train_1000[:, 3] = (X_train_1000[:, 3] - x4_mean) / x4_std\\n\\n# X_train_100[:, 0] = (X_train_100[:, 0] - x1_mean) / x1_std\\n# X_train_100[:, 1] = (X_train_100[:, 1] - x2_mean) / x2_std\\n# X_train_100[:, 2] = (X_train_100[:, 2] - x3_mean) / x3_std\\n# X_train_100[:, 3] = (X_train_100[:, 3] - x4_mean) / x4_std\\n\\n# X_val[:, 0] = (X_val[:, 0] - x1_mean) / x1_std\\n# X_val[:, 1] = (X_val[:, 1] - x2_mean) / x2_std\\n# X_val[:, 2] = (X_val[:, 2] - x3_mean) / x3_std\\n# X_val[:, 3] = (X_val[:, 3] - x4_mean) / x4_std\";\n",
       "                var nbb_formatted_code = \"# # Subtract the mean from x1, x2, and x3 in both the training and validation/test data\\n# X_train_1000[:, 0] = (X_train_1000[:, 0] - x1_mean) / x1_std\\n# X_train_1000[:, 1] = (X_train_1000[:, 1] - x2_mean) / x2_std\\n# X_train_1000[:, 2] = (X_train_1000[:, 2] - x3_mean) / x3_std\\n# X_train_1000[:, 3] = (X_train_1000[:, 3] - x4_mean) / x4_std\\n\\n# X_train_100[:, 0] = (X_train_100[:, 0] - x1_mean) / x1_std\\n# X_train_100[:, 1] = (X_train_100[:, 1] - x2_mean) / x2_std\\n# X_train_100[:, 2] = (X_train_100[:, 2] - x3_mean) / x3_std\\n# X_train_100[:, 3] = (X_train_100[:, 3] - x4_mean) / x4_std\\n\\n# X_val[:, 0] = (X_val[:, 0] - x1_mean) / x1_std\\n# X_val[:, 1] = (X_val[:, 1] - x2_mean) / x2_std\\n# X_val[:, 2] = (X_val[:, 2] - x3_mean) / x3_std\\n# X_val[:, 3] = (X_val[:, 3] - x4_mean) / x4_std\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Subtract the mean from x1, x2, and x3 in both the training and validation/test data\n",
    "# X_train_1000[:, 0] = (X_train_1000[:, 0] - x1_mean) / x1_std\n",
    "# X_train_1000[:, 1] = (X_train_1000[:, 1] - x2_mean) / x2_std\n",
    "# X_train_1000[:, 2] = (X_train_1000[:, 2] - x3_mean) / x3_std\n",
    "# X_train_1000[:, 3] = (X_train_1000[:, 3] - x4_mean) / x4_std\n",
    "\n",
    "# X_train_100[:, 0] = (X_train_100[:, 0] - x1_mean) / x1_std\n",
    "# X_train_100[:, 1] = (X_train_100[:, 1] - x2_mean) / x2_std\n",
    "# X_train_100[:, 2] = (X_train_100[:, 2] - x3_mean) / x3_std\n",
    "# X_train_100[:, 3] = (X_train_100[:, 3] - x4_mean) / x4_std\n",
    "\n",
    "# X_val[:, 0] = (X_val[:, 0] - x1_mean) / x1_std\n",
    "# X_val[:, 1] = (X_val[:, 1] - x2_mean) / x2_std\n",
    "# X_val[:, 2] = (X_val[:, 2] - x3_mean) / x3_std\n",
    "# X_val[:, 3] = (X_val[:, 3] - x4_mean) / x4_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f9fd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# # Calculate the mean and standard deviation of x1, x2, and x3 in the training data\\n# x_mean = np.mean(X_train_1000, axis=0)\\n# x_std = np.std(X_train_1000, axis=0)\\n\\n# # Standardize the data\\n# X_train_1000 = (X_train_1000 - x_mean) / x_std\\n# X_train_100 = (X_train_100 - x_mean) / x_std\\n# X_val = (X_val - x_mean) / x_std\\n\\n# # Normalize the data\\n# X_train_1000 = X_train_1000 / np.sum(X_train_1000, axis=1)[:, np.newaxis]\\n# X_train_100 = X_train_100 / np.sum(X_train_100, axis=1)[:, np.newaxis]\\n# X_val = X_val / np.sum(X_val, axis=1)[:, np.newaxis]\";\n",
       "                var nbb_formatted_code = \"# # Calculate the mean and standard deviation of x1, x2, and x3 in the training data\\n# x_mean = np.mean(X_train_1000, axis=0)\\n# x_std = np.std(X_train_1000, axis=0)\\n\\n# # Standardize the data\\n# X_train_1000 = (X_train_1000 - x_mean) / x_std\\n# X_train_100 = (X_train_100 - x_mean) / x_std\\n# X_val = (X_val - x_mean) / x_std\\n\\n# # Normalize the data\\n# X_train_1000 = X_train_1000 / np.sum(X_train_1000, axis=1)[:, np.newaxis]\\n# X_train_100 = X_train_100 / np.sum(X_train_100, axis=1)[:, np.newaxis]\\n# X_val = X_val / np.sum(X_val, axis=1)[:, np.newaxis]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Calculate the mean and standard deviation of x1, x2, and x3 in the training data\n",
    "# x_mean = np.mean(X_train_1000, axis=0)\n",
    "# x_std = np.std(X_train_1000, axis=0)\n",
    "\n",
    "# # Standardize the data\n",
    "# X_train_1000 = (X_train_1000 - x_mean) / x_std\n",
    "# X_train_100 = (X_train_100 - x_mean) / x_std\n",
    "# X_val = (X_val - x_mean) / x_std\n",
    "\n",
    "# # Normalize the data\n",
    "# X_train_1000 = X_train_1000 / np.sum(X_train_1000, axis=1)[:, np.newaxis]\n",
    "# X_train_100 = X_train_100 / np.sum(X_train_100, axis=1)[:, np.newaxis]\n",
    "# X_val = X_val / np.sum(X_val, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469fad5",
   "metadata": {},
   "source": [
    "For that purpose, you have training data (xi, yi)\n",
    "mi=1 available. Unfortunately,\n",
    "the fourth sensor MFC4 had a slight malfunction at the time when the training data were produced. As a consequence, the values x4 are on average\n",
    "higher than their counterparts x1, x2 and x3. Be aware that the same effect\n",
    "is not present in the validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422cf778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Preprocess the training data to account for the issue with the fourth sensor MFC4\\nX_train_100[:, 3] = X_train_100[:, 3] * (\\n    np.mean(X_train_100[:, :3], axis=1) / np.mean(X_train_100[:, 3])\\n)\\nX_train_1000[:, 3] = X_train_1000[:, 3] * (\\n    np.mean(X_train_1000[:, :3], axis=1) / np.mean(X_train_1000[:, 3])\\n)\";\n",
       "                var nbb_formatted_code = \"# Preprocess the training data to account for the issue with the fourth sensor MFC4\\nX_train_100[:, 3] = X_train_100[:, 3] * (\\n    np.mean(X_train_100[:, :3], axis=1) / np.mean(X_train_100[:, 3])\\n)\\nX_train_1000[:, 3] = X_train_1000[:, 3] * (\\n    np.mean(X_train_1000[:, :3], axis=1) / np.mean(X_train_1000[:, 3])\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the training data to account for the issue with the fourth sensor MFC4\n",
    "X_train_100[:, 3] = X_train_100[:, 3] * (\n",
    "    np.mean(X_train_100[:, :3], axis=1) / np.mean(X_train_100[:, 3])\n",
    ")\n",
    "X_train_1000[:, 3] = X_train_1000[:, 3] * (\n",
    "    np.mean(X_train_1000[:, :3], axis=1) / np.mean(X_train_1000[:, 3])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0397bb",
   "metadata": {},
   "source": [
    "### 2. Train a standard fully connected neural network. Hyperparameters\n",
    "\n",
    "like number of epochs, batch size, optimizer, learning rate, depth and\n",
    "width of the network, activation and loss functions – all up to you. You\n",
    "can use a framework like KerasTuner to optimize hyperparameters, or\n",
    "simple for-loops if you prefer that. Anyway, you should use the validation data in order to evaluate and compare candidate hyperparameter\n",
    "configurations. Save the model as model standard [m].h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3991fadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def standard_model(hp):\\n    model = Sequential()\\n    model.add(\\n        Dense(\\n            units=hp.Int(\\\"units_1\\\", min_value=32, max_value=512, step=32),\\n            input_shape=(4,),\\n            activation=hp.Choice(\\\"activation_1\\\", values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"]),\\n        )\\n    )\\n\\n    model.add(\\n        Dense(\\n            units=hp.Int(f\\\"units_2\\\", min_value=16, max_value=128, step=16),\\n            activation=hp.Choice(\\n                f\\\"activation_2\\\",\\n                values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"],\\n            ),\\n        )\\n    )\\n\\n    model.add(Dense(2, activation=\\\"softmax\\\"))\\n\\n    # Set optimizer and learning rate\\n    optimizer = hp.Choice(\\\"optimizer\\\", values=[\\\"adam\\\", \\\"adagrad\\\", \\\"nadam\\\", \\\"rmsprop\\\"])\\n    learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-1, 1e-2, 1e-3, 1e-4])\\n\\n    if optimizer == \\\"adam\\\":\\n        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\\n    elif optimizer == \\\"adagrad\\\":\\n        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\\n    elif optimizer == \\\"rmsprop\\\":\\n        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\\n    else:\\n        optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\\n\\n    model.compile(\\n        optimizer=optimizer,\\n        loss=\\\"mean_squared_error\\\",\\n        metrics=[\\\"mean_absolute_error\\\"],\\n    )\\n\\n    return model\";\n",
       "                var nbb_formatted_code = \"def standard_model(hp):\\n    model = Sequential()\\n    model.add(\\n        Dense(\\n            units=hp.Int(\\\"units_1\\\", min_value=32, max_value=512, step=32),\\n            input_shape=(4,),\\n            activation=hp.Choice(\\\"activation_1\\\", values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"]),\\n        )\\n    )\\n\\n    model.add(\\n        Dense(\\n            units=hp.Int(f\\\"units_2\\\", min_value=16, max_value=128, step=16),\\n            activation=hp.Choice(\\n                f\\\"activation_2\\\",\\n                values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"],\\n            ),\\n        )\\n    )\\n\\n    model.add(Dense(2, activation=\\\"softmax\\\"))\\n\\n    # Set optimizer and learning rate\\n    optimizer = hp.Choice(\\\"optimizer\\\", values=[\\\"adam\\\", \\\"adagrad\\\", \\\"nadam\\\", \\\"rmsprop\\\"])\\n    learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-1, 1e-2, 1e-3, 1e-4])\\n\\n    if optimizer == \\\"adam\\\":\\n        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\\n    elif optimizer == \\\"adagrad\\\":\\n        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\\n    elif optimizer == \\\"rmsprop\\\":\\n        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\\n    else:\\n        optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\\n\\n    model.compile(\\n        optimizer=optimizer,\\n        loss=\\\"mean_squared_error\\\",\\n        metrics=[\\\"mean_absolute_error\\\"],\\n    )\\n\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def standard_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Int(\"units_1\", min_value=32, max_value=512, step=32),\n",
    "            input_shape=(4,),\n",
    "            activation=hp.Choice(\"activation_1\", values=[\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Int(f\"units_2\", min_value=16, max_value=128, step=16),\n",
    "            activation=hp.Choice(\n",
    "                f\"activation_2\",\n",
    "                values=[\"relu\", \"tanh\", \"sigmoid\"],\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    # Set optimizer and learning rate\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"adam\", \"adagrad\", \"nadam\", \"rmsprop\"])\n",
    "    learning_rate = hp.Choice(\"learning_rate\", values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adagrad\":\n",
    "        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5c0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# def with_all_standard_model(hp):\\n#     model = Sequential()\\n#     model.add(\\n#         Dense(\\n#             units=hp.Int(\\\"units_1\\\", min_value=32, max_value=512, step=32),\\n#             input_shape=(4,),\\n#             activation=hp.Choice(\\\"activation_1\\\", values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"]),\\n#         )\\n#     )\\n\\n#     model.add(Dropout(hp.Float(\\\"dropout_1\\\", min_value=0.2, max_value=0.5, step=0.1)))\\n#     model.add(BatchNormalization())\\n\\n#     model.add(\\n#         Dense(\\n#             units=hp.Int(f\\\"units_2\\\", min_value=16, max_value=128, step=16),\\n#             activation=hp.Choice(\\n#                 f\\\"activation_2\\\",\\n#                 values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"],\\n#             ),\\n#         )\\n#     )\\n\\n#     model.add(Dropout(hp.Float(f\\\"dropout_2\\\", min_value=0.2, max_value=0.5, step=0.1)))\\n#     model.add(BatchNormalization())\\n\\n#     model.add(Dense(2, activation=\\\"softmax\\\"))\\n\\n#     # Set optimizer and learning rate\\n#     optimizer = hp.Choice(\\\"optimizer\\\", values=[\\\"adam\\\", \\\"adagrad\\\", \\\"nadam\\\", \\\"rmsprop\\\"])\\n#     learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-1, 1e-2, 1e-3, 1e-4])\\n\\n#     if optimizer == \\\"adam\\\":\\n#         optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\\n#     elif optimizer == \\\"adagrad\\\":\\n#         optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\\n#     elif optimizer == \\\"rmsprop\\\":\\n#         optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\\n#     else:\\n#         optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\\n\\n#     model.compile(\\n#         optimizer=optimizer,\\n#         loss=\\\"mean_squared_error\\\",\\n#         metrics=[\\\"mean_absolute_error\\\"],\\n#     )\\n\\n#     # Add regularization\\n#     if hp.Boolean(\\\"use_regularization\\\"):\\n#         l1_reg = hp.Float(\\\"l1_reg\\\", min_value=1e-6, max_value=1e-2, sampling=\\\"log\\\")\\n#         l2_reg = hp.Float(\\\"l2_reg\\\", min_value=1e-6, max_value=1e-2, sampling=\\\"log\\\")\\n#         model.add(keras.layers.ActivityRegularization(l1=l1_reg, l2=l2_reg))\\n\\n#     return model\";\n",
       "                var nbb_formatted_code = \"# def with_all_standard_model(hp):\\n#     model = Sequential()\\n#     model.add(\\n#         Dense(\\n#             units=hp.Int(\\\"units_1\\\", min_value=32, max_value=512, step=32),\\n#             input_shape=(4,),\\n#             activation=hp.Choice(\\\"activation_1\\\", values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"]),\\n#         )\\n#     )\\n\\n#     model.add(Dropout(hp.Float(\\\"dropout_1\\\", min_value=0.2, max_value=0.5, step=0.1)))\\n#     model.add(BatchNormalization())\\n\\n#     model.add(\\n#         Dense(\\n#             units=hp.Int(f\\\"units_2\\\", min_value=16, max_value=128, step=16),\\n#             activation=hp.Choice(\\n#                 f\\\"activation_2\\\",\\n#                 values=[\\\"relu\\\", \\\"tanh\\\", \\\"sigmoid\\\"],\\n#             ),\\n#         )\\n#     )\\n\\n#     model.add(Dropout(hp.Float(f\\\"dropout_2\\\", min_value=0.2, max_value=0.5, step=0.1)))\\n#     model.add(BatchNormalization())\\n\\n#     model.add(Dense(2, activation=\\\"softmax\\\"))\\n\\n#     # Set optimizer and learning rate\\n#     optimizer = hp.Choice(\\\"optimizer\\\", values=[\\\"adam\\\", \\\"adagrad\\\", \\\"nadam\\\", \\\"rmsprop\\\"])\\n#     learning_rate = hp.Choice(\\\"learning_rate\\\", values=[1e-1, 1e-2, 1e-3, 1e-4])\\n\\n#     if optimizer == \\\"adam\\\":\\n#         optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\\n#     elif optimizer == \\\"adagrad\\\":\\n#         optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\\n#     elif optimizer == \\\"rmsprop\\\":\\n#         optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\\n#     else:\\n#         optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\\n\\n#     model.compile(\\n#         optimizer=optimizer,\\n#         loss=\\\"mean_squared_error\\\",\\n#         metrics=[\\\"mean_absolute_error\\\"],\\n#     )\\n\\n#     # Add regularization\\n#     if hp.Boolean(\\\"use_regularization\\\"):\\n#         l1_reg = hp.Float(\\\"l1_reg\\\", min_value=1e-6, max_value=1e-2, sampling=\\\"log\\\")\\n#         l2_reg = hp.Float(\\\"l2_reg\\\", min_value=1e-6, max_value=1e-2, sampling=\\\"log\\\")\\n#         model.add(keras.layers.ActivityRegularization(l1=l1_reg, l2=l2_reg))\\n\\n#     return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def with_all_standard_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(\n",
    "#         Dense(\n",
    "#             units=hp.Int(\"units_1\", min_value=32, max_value=512, step=32),\n",
    "#             input_shape=(4,),\n",
    "#             activation=hp.Choice(\"activation_1\", values=[\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     model.add(Dropout(hp.Float(\"dropout_1\", min_value=0.2, max_value=0.5, step=0.1)))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(\n",
    "#         Dense(\n",
    "#             units=hp.Int(f\"units_2\", min_value=16, max_value=128, step=16),\n",
    "#             activation=hp.Choice(\n",
    "#                 f\"activation_2\",\n",
    "#                 values=[\"relu\", \"tanh\", \"sigmoid\"],\n",
    "#             ),\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     model.add(Dropout(hp.Float(f\"dropout_2\", min_value=0.2, max_value=0.5, step=0.1)))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "#     # Set optimizer and learning rate\n",
    "#     optimizer = hp.Choice(\"optimizer\", values=[\"adam\", \"adagrad\", \"nadam\", \"rmsprop\"])\n",
    "#     learning_rate = hp.Choice(\"learning_rate\", values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "#     if optimizer == \"adam\":\n",
    "#         optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     elif optimizer == \"adagrad\":\n",
    "#         optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "#     elif optimizer == \"rmsprop\":\n",
    "#         optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "#     else:\n",
    "#         optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=optimizer,\n",
    "#         loss=\"mean_squared_error\",\n",
    "#         metrics=[\"mean_absolute_error\"],\n",
    "#     )\n",
    "\n",
    "#     # Add regularization\n",
    "#     if hp.Boolean(\"use_regularization\"):\n",
    "#         l1_reg = hp.Float(\"l1_reg\", min_value=1e-6, max_value=1e-2, sampling=\"log\")\n",
    "#         l2_reg = hp.Float(\"l2_reg\", min_value=1e-6, max_value=1e-2, sampling=\"log\")\n",
    "#         model.add(keras.layers.ActivityRegularization(l1=l1_reg, l2=l2_reg))\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1443b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 06s]\n",
      "val_loss: 0.570703387260437\n",
      "\n",
      "Best val_loss So Far: 0.42471805214881897\n",
      "Total elapsed time: 00h 15m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"tuner_100 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_100\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_100.search(\\n    X_train_100,\\n    y_train_100,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n#     verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"tuner_100 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_100\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_100.search(\\n    X_train_100,\\n    y_train_100,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n    #     verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_100 = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"standard_model_100\",\n",
    ")\n",
    "# Search for the best hyperparameters\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "tuner_100.search(\n",
    "    X_train_100,\n",
    "    y_train_100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    #     verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4ee59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"best_hps_100 = tuner_100.get_best_hyperparameters(num_trials=1)[0]\\nmodel_100 = tuner_100.hypermodel.build(best_hps_100)\";\n",
       "                var nbb_formatted_code = \"best_hps_100 = tuner_100.get_best_hyperparameters(num_trials=1)[0]\\nmodel_100 = tuner_100.hypermodel.build(best_hps_100)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_100 = tuner_100.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_100 = tuner_100.hypermodel.build(best_hps_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7654f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 67ms/step - loss: 0.5626 - mean_absolute_error: 0.6136 - val_loss: 0.5205 - val_mean_absolute_error: 0.5889\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5307 - mean_absolute_error: 0.5975 - val_loss: 0.4865 - val_mean_absolute_error: 0.5719\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5041 - mean_absolute_error: 0.5789 - val_loss: 0.4681 - val_mean_absolute_error: 0.5580\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4826 - mean_absolute_error: 0.5714 - val_loss: 0.4527 - val_mean_absolute_error: 0.5583\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4704 - mean_absolute_error: 0.5608 - val_loss: 0.4359 - val_mean_absolute_error: 0.5425\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4584 - mean_absolute_error: 0.5565 - val_loss: 0.4303 - val_mean_absolute_error: 0.5393\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4545 - mean_absolute_error: 0.5529 - val_loss: 0.4374 - val_mean_absolute_error: 0.5419\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4551 - mean_absolute_error: 0.5556 - val_loss: 0.4266 - val_mean_absolute_error: 0.5380\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4532 - mean_absolute_error: 0.5496 - val_loss: 0.4265 - val_mean_absolute_error: 0.5358\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4524 - mean_absolute_error: 0.5485 - val_loss: 0.4270 - val_mean_absolute_error: 0.5358\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4524 - mean_absolute_error: 0.5484 - val_loss: 0.4276 - val_mean_absolute_error: 0.5359\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4525 - mean_absolute_error: 0.5480 - val_loss: 0.4321 - val_mean_absolute_error: 0.5361\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4529 - mean_absolute_error: 0.5482 - val_loss: 0.4359 - val_mean_absolute_error: 0.5372\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4536 - mean_absolute_error: 0.5487 - val_loss: 0.4311 - val_mean_absolute_error: 0.5357\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4529 - mean_absolute_error: 0.5486 - val_loss: 0.4297 - val_mean_absolute_error: 0.5357\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4527 - mean_absolute_error: 0.5484 - val_loss: 0.4379 - val_mean_absolute_error: 0.5401\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4563 - mean_absolute_error: 0.5516 - val_loss: 0.4389 - val_mean_absolute_error: 0.5414\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4554 - mean_absolute_error: 0.5525 - val_loss: 0.4357 - val_mean_absolute_error: 0.5485\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4583 - mean_absolute_error: 0.5508 - val_loss: 0.4315 - val_mean_absolute_error: 0.5370\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Train the model on the training set\\nhistory_100 = model_100.fit(\\n    X_train_100,\\n    y_train_100,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_formatted_code = \"# Train the model on the training set\\nhistory_100 = model_100.fit(\\n    X_train_100,\\n    y_train_100,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history_100 = model_100.fit(\n",
    "    X_train_100,\n",
    "    y_train_100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fcc73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 936us/step - loss: 0.4315 - mean_absolute_error: 0.5370\n",
      "Validation loss: 0.432\n",
      "Validation accuracy: 0.537\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_100.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_100.save(\\\"models/model_standard_100.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_100.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_100.save(\\\"models/model_standard_100.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_acc = model_100.evaluate(X_val, y_val)\n",
    "print(\"Validation loss: {:.3f}\".format(val_loss))\n",
    "print(\"Validation accuracy: {:.3f}\".format(val_acc))\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_100.save(\"models/model_standard_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4caee53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 14s]\n",
      "val_loss: 0.4246198534965515\n",
      "\n",
      "Best val_loss So Far: 0.4234359562397003\n",
      "Total elapsed time: 00h 17m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"tuner_1000 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_1000\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_1000.search(\\n    X_train_1000,\\n    y_train_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n#     verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"tuner_1000 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_1000\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_1000.search(\\n    X_train_1000,\\n    y_train_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n    #     verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_1000 = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"standard_model_1000\",\n",
    ")\n",
    "# Search for the best hyperparameters\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "tuner_1000.search(\n",
    "    X_train_1000,\n",
    "    y_train_1000,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "#     verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0b3931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"best_hps_1000 = tuner_1000.get_best_hyperparameters(num_trials=1)[0]\\nmodel_1000 = tuner_1000.hypermodel.build(best_hps_1000)\";\n",
       "                var nbb_formatted_code = \"best_hps_1000 = tuner_1000.get_best_hyperparameters(num_trials=1)[0]\\nmodel_1000 = tuner_1000.hypermodel.build(best_hps_1000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_1000 = tuner_1000.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_1000 = tuner_1000.hypermodel.build(best_hps_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a634542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.4572 - mean_absolute_error: 0.5592 - val_loss: 0.4265 - val_mean_absolute_error: 0.5356\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4283 - mean_absolute_error: 0.5398 - val_loss: 0.4256 - val_mean_absolute_error: 0.5364\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4280 - mean_absolute_error: 0.5400 - val_loss: 0.4256 - val_mean_absolute_error: 0.5365\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4279 - mean_absolute_error: 0.5396 - val_loss: 0.4343 - val_mean_absolute_error: 0.5425\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4281 - mean_absolute_error: 0.5399 - val_loss: 0.4271 - val_mean_absolute_error: 0.5368\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4276 - mean_absolute_error: 0.5395 - val_loss: 0.4247 - val_mean_absolute_error: 0.5359\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4275 - mean_absolute_error: 0.5395 - val_loss: 0.4262 - val_mean_absolute_error: 0.5372\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4280 - mean_absolute_error: 0.5401 - val_loss: 0.4248 - val_mean_absolute_error: 0.5358\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4279 - mean_absolute_error: 0.5395 - val_loss: 0.4285 - val_mean_absolute_error: 0.5374\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4274 - mean_absolute_error: 0.5394 - val_loss: 0.4385 - val_mean_absolute_error: 0.5437\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4280 - mean_absolute_error: 0.5400 - val_loss: 0.4263 - val_mean_absolute_error: 0.5370\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4278 - mean_absolute_error: 0.5394 - val_loss: 0.4293 - val_mean_absolute_error: 0.5415\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4277 - mean_absolute_error: 0.5395 - val_loss: 0.4246 - val_mean_absolute_error: 0.5359\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4276 - mean_absolute_error: 0.5396 - val_loss: 0.4289 - val_mean_absolute_error: 0.5384\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4274 - mean_absolute_error: 0.5397 - val_loss: 0.4248 - val_mean_absolute_error: 0.5359\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4273 - mean_absolute_error: 0.5396 - val_loss: 0.4276 - val_mean_absolute_error: 0.5370\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4276 - mean_absolute_error: 0.5395 - val_loss: 0.4265 - val_mean_absolute_error: 0.5363\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4276 - mean_absolute_error: 0.5393 - val_loss: 0.4251 - val_mean_absolute_error: 0.5367\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4273 - mean_absolute_error: 0.5395 - val_loss: 0.4255 - val_mean_absolute_error: 0.5357\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4271 - mean_absolute_error: 0.5393 - val_loss: 0.4247 - val_mean_absolute_error: 0.5358\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4272 - mean_absolute_error: 0.5396 - val_loss: 0.4267 - val_mean_absolute_error: 0.5370\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4271 - mean_absolute_error: 0.5393 - val_loss: 0.4257 - val_mean_absolute_error: 0.5361\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4272 - mean_absolute_error: 0.5397 - val_loss: 0.4258 - val_mean_absolute_error: 0.5362\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Train the model on the training set\\nhistory_1000 = model_1000.fit(\\n    X_train_1000,\\n    y_train_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_formatted_code = \"# Train the model on the training set\\nhistory_1000 = model_1000.fit(\\n    X_train_1000,\\n    y_train_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history_1000 = model_1000.fit(\n",
    "    X_train_1000,\n",
    "    y_train_1000,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83d3409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4258 - mean_absolute_error: 0.5362\n",
      "Validation loss: 0.426\n",
      "Validation accuracy: 0.536\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_1000.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_1000.save(\\\"models/model_standard_1000.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_1000.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_1000.save(\\\"models/model_standard_1000.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_acc = model_1000.evaluate(X_val, y_val)\n",
    "print(\"Validation loss: {:.3f}\".format(val_loss))\n",
    "print(\"Validation accuracy: {:.3f}\".format(val_acc))\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_1000.save(\"models/model_standard_1000.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1862bf",
   "metadata": {},
   "source": [
    "### 3. Augment the dataset. \n",
    "\n",
    "Each training example (x, y) can be complemented by seven additional virtual examples as illustrated in Figure 1.\n",
    "Clockwise rotations and flips on input data x are obtained as described\n",
    "above. A clockwise rotation on output data y is obtained through\n",
    "y90 = (y2, −y1) and a flip along the vertical axis on the same data is\n",
    "represented by yf lipped = (−y1, y2). All other operations (rotation angles and associated flips) can be computed by subsequent application\n",
    "of these two operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c4a150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def augment_data(x_train, y_train):\\n    # initialize empty lists for augmented data and labels\\n    x_train_aug = []\\n    y_train_aug = []\\n\\n    for i in range(len(x_train)):\\n        x_train_aug.append(x_train[i])\\n        y_train_aug.append(y_train[i])\\n\\n        # 90 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([-x_train[i][1], x_train[i][0], -x_train[i][3], x_train[i][2]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([y_train[i][1], -y_train[i][0]])))\\n\\n        # 180 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([-x_train[i][2], -x_train[i][3], x_train[i][0], x_train[i][1]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][0], -y_train[i][1]])))\\n\\n        # 270 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([x_train[i][3], -x_train[i][2], x_train[i][1], -x_train[i][0]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][1], y_train[i][0]])))\\n\\n        # vertical flip\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([x_train[i][2], x_train[i][3], x_train[i][0], x_train[i][1]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][0], y_train[i][1]])))\\n\\n        # horizontal flip + 90 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array(\\n                    [-x_train[i][1], -x_train[i][0], -x_train[i][3], -x_train[i][2]]\\n                )\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][1], y_train[i][0]])))\\n\\n        # horizontal flip + 180 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([-x_train[i][2], -x_train[i][1], x_train[i][0], x_train[i][3]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([y_train[i][0], y_train[i][1]])))\\n\\n        # horizontal flip + 270 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([x_train[i][3], x_train[i][2], -x_train[i][1], x_train[i][0]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([y_train[i][1], -y_train[i][0]])))\\n    return x_train_aug, y_train_aug\";\n",
       "                var nbb_formatted_code = \"def augment_data(x_train, y_train):\\n    # initialize empty lists for augmented data and labels\\n    x_train_aug = []\\n    y_train_aug = []\\n\\n    for i in range(len(x_train)):\\n        x_train_aug.append(x_train[i])\\n        y_train_aug.append(y_train[i])\\n\\n        # 90 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([-x_train[i][1], x_train[i][0], -x_train[i][3], x_train[i][2]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([y_train[i][1], -y_train[i][0]])))\\n\\n        # 180 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([-x_train[i][2], -x_train[i][3], x_train[i][0], x_train[i][1]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][0], -y_train[i][1]])))\\n\\n        # 270 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([x_train[i][3], -x_train[i][2], x_train[i][1], -x_train[i][0]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][1], y_train[i][0]])))\\n\\n        # vertical flip\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([x_train[i][2], x_train[i][3], x_train[i][0], x_train[i][1]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][0], y_train[i][1]])))\\n\\n        # horizontal flip + 90 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array(\\n                    [-x_train[i][1], -x_train[i][0], -x_train[i][3], -x_train[i][2]]\\n                )\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([-y_train[i][1], y_train[i][0]])))\\n\\n        # horizontal flip + 180 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([-x_train[i][2], -x_train[i][1], x_train[i][0], x_train[i][3]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([y_train[i][0], y_train[i][1]])))\\n\\n        # horizontal flip + 270 degree clockwise rotation\\n        x_train_aug.append(\\n            np.flip(\\n                np.array([x_train[i][3], x_train[i][2], -x_train[i][1], x_train[i][0]])\\n            )\\n        )\\n        y_train_aug.append(np.flip(np.array([y_train[i][1], -y_train[i][0]])))\\n    return x_train_aug, y_train_aug\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def augment_data(x_train, y_train):\n",
    "    # initialize empty lists for augmented data and labels\n",
    "    x_train_aug = []\n",
    "    y_train_aug = []\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        x_train_aug.append(x_train[i])\n",
    "        y_train_aug.append(y_train[i])\n",
    "\n",
    "        # 90 degree clockwise rotation\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array([-x_train[i][1], x_train[i][0], -x_train[i][3], x_train[i][2]])\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([y_train[i][1], -y_train[i][0]])))\n",
    "\n",
    "        # 180 degree clockwise rotation\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array([-x_train[i][2], -x_train[i][3], x_train[i][0], x_train[i][1]])\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([-y_train[i][0], -y_train[i][1]])))\n",
    "\n",
    "        # 270 degree clockwise rotation\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array([x_train[i][3], -x_train[i][2], x_train[i][1], -x_train[i][0]])\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([-y_train[i][1], y_train[i][0]])))\n",
    "\n",
    "        # vertical flip\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array([x_train[i][2], x_train[i][3], x_train[i][0], x_train[i][1]])\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([-y_train[i][0], y_train[i][1]])))\n",
    "\n",
    "        # horizontal flip + 90 degree clockwise rotation\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array(\n",
    "                    [-x_train[i][1], -x_train[i][0], -x_train[i][3], -x_train[i][2]]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([-y_train[i][1], y_train[i][0]])))\n",
    "\n",
    "        # horizontal flip + 180 degree clockwise rotation\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array([-x_train[i][2], -x_train[i][1], x_train[i][0], x_train[i][3]])\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([y_train[i][0], y_train[i][1]])))\n",
    "\n",
    "        # horizontal flip + 270 degree clockwise rotation\n",
    "        x_train_aug.append(\n",
    "            np.flip(\n",
    "                np.array([x_train[i][3], x_train[i][2], -x_train[i][1], x_train[i][0]])\n",
    "            )\n",
    "        )\n",
    "        y_train_aug.append(np.flip(np.array([y_train[i][1], -y_train[i][0]])))\n",
    "    return x_train_aug, y_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5136b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Augment the training data with the augment_data function for the X_train_100 and y_train_100 data\\nx_train_augmented, y_train_augmented = augment_data(X_train_100, y_train_100)\\nx_train_augmented_1000, y_train_augmented_1000 = augment_data(\\n    X_train_1000, y_train_1000\\n)\\n\\n# Convert the augmented data and labels to numpy arrays\\nX_train_augmented = np.array(x_train_augmented)\\ny_train_augmented = np.array(y_train_augmented)\\nX_train_augmented_1000 = np.array(x_train_augmented_1000)\\ny_train_augmented_1000 = np.array(y_train_augmented_1000)\";\n",
       "                var nbb_formatted_code = \"# Augment the training data with the augment_data function for the X_train_100 and y_train_100 data\\nx_train_augmented, y_train_augmented = augment_data(X_train_100, y_train_100)\\nx_train_augmented_1000, y_train_augmented_1000 = augment_data(\\n    X_train_1000, y_train_1000\\n)\\n\\n# Convert the augmented data and labels to numpy arrays\\nX_train_augmented = np.array(x_train_augmented)\\ny_train_augmented = np.array(y_train_augmented)\\nX_train_augmented_1000 = np.array(x_train_augmented_1000)\\ny_train_augmented_1000 = np.array(y_train_augmented_1000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Augment the training data with the augment_data function for the X_train_100 and y_train_100 data\n",
    "x_train_augmented, y_train_augmented = augment_data(X_train_100, y_train_100)\n",
    "x_train_augmented_1000, y_train_augmented_1000 = augment_data(\n",
    "    X_train_1000, y_train_1000\n",
    ")\n",
    "\n",
    "# Convert the augmented data and labels to numpy arrays\n",
    "X_train_augmented = np.array(x_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "X_train_augmented_1000 = np.array(x_train_augmented_1000)\n",
    "y_train_augmented_1000 = np.array(y_train_augmented_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e2e58",
   "metadata": {},
   "source": [
    "### 4. Repeat 2. \n",
    "on the augmented dataset. Save this model as model standard [m] augmented.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94a79b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 17s]\n",
      "val_loss: 0.5613260269165039\n",
      "\n",
      "Best val_loss So Far: 0.47030162811279297\n",
      "Total elapsed time: 00h 15m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"tuner_100_aug = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_aug_100\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_100_aug.search(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n#     verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"tuner_100_aug = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_aug_100\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_100_aug.search(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n    #     verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_100_aug = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"standard_model_aug_100\",\n",
    ")\n",
    "# Search for the best hyperparameters\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "tuner_100_aug.search(\n",
    "    X_train_augmented,\n",
    "    y_train_augmented,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    #     verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e442073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"best_hps_aug_100 = tuner_100_aug.get_best_hyperparameters(num_trials=1)[0]\\nmodel_aug_100 = tuner_100_aug.hypermodel.build(best_hps_aug_100)\";\n",
       "                var nbb_formatted_code = \"best_hps_aug_100 = tuner_100_aug.get_best_hyperparameters(num_trials=1)[0]\\nmodel_aug_100 = tuner_100_aug.hypermodel.build(best_hps_aug_100)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_aug_100 = tuner_100_aug.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_aug_100 = tuner_100_aug.hypermodel.build(best_hps_aug_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d176e4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 10ms/step - loss: 0.5794 - mean_absolute_error: 0.6217 - val_loss: 0.5620 - val_mean_absolute_error: 0.6123\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5561 - mean_absolute_error: 0.6071 - val_loss: 0.5705 - val_mean_absolute_error: 0.6192\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5535 - mean_absolute_error: 0.6059 - val_loss: 0.5834 - val_mean_absolute_error: 0.6241\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5339 - mean_absolute_error: 0.5963 - val_loss: 0.5740 - val_mean_absolute_error: 0.6185\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5308 - mean_absolute_error: 0.5937 - val_loss: 0.5662 - val_mean_absolute_error: 0.6138\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5254 - mean_absolute_error: 0.5895 - val_loss: 0.5649 - val_mean_absolute_error: 0.6128\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5205 - mean_absolute_error: 0.5901 - val_loss: 0.5592 - val_mean_absolute_error: 0.6125\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5102 - mean_absolute_error: 0.5839 - val_loss: 0.5460 - val_mean_absolute_error: 0.6035\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5176 - mean_absolute_error: 0.5900 - val_loss: 0.5524 - val_mean_absolute_error: 0.6052\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5157 - mean_absolute_error: 0.5853 - val_loss: 0.5366 - val_mean_absolute_error: 0.5972\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5015 - mean_absolute_error: 0.5805 - val_loss: 0.5290 - val_mean_absolute_error: 0.5909\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5004 - mean_absolute_error: 0.5784 - val_loss: 0.5836 - val_mean_absolute_error: 0.6216\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4970 - mean_absolute_error: 0.5765 - val_loss: 0.5659 - val_mean_absolute_error: 0.6081\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4963 - mean_absolute_error: 0.5752 - val_loss: 0.5504 - val_mean_absolute_error: 0.6061\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4956 - mean_absolute_error: 0.5750 - val_loss: 0.5595 - val_mean_absolute_error: 0.6084\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4964 - mean_absolute_error: 0.5767 - val_loss: 0.5104 - val_mean_absolute_error: 0.5829\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5003 - mean_absolute_error: 0.5784 - val_loss: 0.5471 - val_mean_absolute_error: 0.6052\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4974 - mean_absolute_error: 0.5759 - val_loss: 0.5219 - val_mean_absolute_error: 0.5913\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4926 - mean_absolute_error: 0.5724 - val_loss: 0.5388 - val_mean_absolute_error: 0.5978\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4884 - mean_absolute_error: 0.5719 - val_loss: 0.5571 - val_mean_absolute_error: 0.6106\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4859 - mean_absolute_error: 0.5701 - val_loss: 0.5322 - val_mean_absolute_error: 0.5909\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4884 - mean_absolute_error: 0.5725 - val_loss: 0.5453 - val_mean_absolute_error: 0.6037\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4901 - mean_absolute_error: 0.5716 - val_loss: 0.5647 - val_mean_absolute_error: 0.6127\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4924 - mean_absolute_error: 0.5762 - val_loss: 0.5393 - val_mean_absolute_error: 0.6000\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4873 - mean_absolute_error: 0.5712 - val_loss: 0.5378 - val_mean_absolute_error: 0.6006\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4876 - mean_absolute_error: 0.5725 - val_loss: 0.5436 - val_mean_absolute_error: 0.6018\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# Train the model on the training set\\nhistory_aug_100 = model_aug_100.fit(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_formatted_code = \"# Train the model on the training set\\nhistory_aug_100 = model_aug_100.fit(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history_aug_100 = model_aug_100.fit(\n",
    "    X_train_augmented,\n",
    "    y_train_augmented,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cfb661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5436 - mean_absolute_error: 0.6018\n",
      "Validation loss: 0.544\n",
      "Validation accuracy: 0.602\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_aug_100.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_aug_100.save(\\\"models/model_standard_100_augmented.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_aug_100.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_aug_100.save(\\\"models/model_standard_100_augmented.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_acc = model_aug_100.evaluate(X_val, y_val)\n",
    "print(\"Validation loss: {:.3f}\".format(val_loss))\n",
    "print(\"Validation accuracy: {:.3f}\".format(val_acc))\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_aug_100.save(\"models/model_standard_100_augmented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4461898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 32s]\n",
      "val_loss: 0.5588197112083435\n",
      "\n",
      "Best val_loss So Far: 0.44556111097335815\n",
      "Total elapsed time: 00h 28m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"tuner_1000_aug = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_aug_1000\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_1000_aug.search(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n#     verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"tuner_1000_aug = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=100,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"my_dir\\\",\\n    project_name=\\\"standard_model_aug_1000\\\",\\n)\\n# Search for the best hyperparameters\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\ntuner_1000_aug.search(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n    #     verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_1000_aug = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"standard_model_aug_1000\",\n",
    ")\n",
    "# Search for the best hyperparameters\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "tuner_1000_aug.search(\n",
    "    X_train_augmented_1000,\n",
    "    y_train_augmented_1000,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    #     verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfffff40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"best_hps_aug_1000 = tuner_1000_aug.get_best_hyperparameters(num_trials=1)[0]\\nmodel_aug_1000 = tuner_1000_aug.hypermodel.build(best_hps_aug_1000)\";\n",
       "                var nbb_formatted_code = \"best_hps_aug_1000 = tuner_1000_aug.get_best_hyperparameters(num_trials=1)[0]\\nmodel_aug_1000 = tuner_1000_aug.hypermodel.build(best_hps_aug_1000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_aug_1000 = tuner_1000_aug.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_aug_1000 = tuner_1000_aug.hypermodel.build(best_hps_aug_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b695fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5444 - mean_absolute_error: 0.6042 - val_loss: 0.5239 - val_mean_absolute_error: 0.5877\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5180 - mean_absolute_error: 0.5906 - val_loss: 0.5111 - val_mean_absolute_error: 0.5826\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5092 - mean_absolute_error: 0.5857 - val_loss: 0.5737 - val_mean_absolute_error: 0.6164\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5025 - mean_absolute_error: 0.5818 - val_loss: 0.4996 - val_mean_absolute_error: 0.5800\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4956 - mean_absolute_error: 0.5785 - val_loss: 0.5976 - val_mean_absolute_error: 0.6236\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4922 - mean_absolute_error: 0.5763 - val_loss: 0.4655 - val_mean_absolute_error: 0.5690\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4874 - mean_absolute_error: 0.5736 - val_loss: 0.4906 - val_mean_absolute_error: 0.5821\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4851 - mean_absolute_error: 0.5727 - val_loss: 0.4996 - val_mean_absolute_error: 0.5830\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4848 - mean_absolute_error: 0.5716 - val_loss: 0.5140 - val_mean_absolute_error: 0.5972\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4820 - mean_absolute_error: 0.5711 - val_loss: 0.4878 - val_mean_absolute_error: 0.5711\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4808 - mean_absolute_error: 0.5699 - val_loss: 0.5149 - val_mean_absolute_error: 0.5950\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4797 - mean_absolute_error: 0.5690 - val_loss: 0.4991 - val_mean_absolute_error: 0.6004\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4792 - mean_absolute_error: 0.5692 - val_loss: 0.5046 - val_mean_absolute_error: 0.5819\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4778 - mean_absolute_error: 0.5688 - val_loss: 0.5325 - val_mean_absolute_error: 0.6004\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4760 - mean_absolute_error: 0.5679 - val_loss: 0.5690 - val_mean_absolute_error: 0.6385\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4739 - mean_absolute_error: 0.5665 - val_loss: 0.6276 - val_mean_absolute_error: 0.6574\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Train the model on the training set\\nhistory_aug_1000 = model_aug_1000.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_formatted_code = \"# Train the model on the training set\\nhistory_aug_1000 = model_aug_1000.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history_aug_1000 = model_aug_1000.fit(\n",
    "    X_train_augmented_1000,\n",
    "    y_train_augmented_1000,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9093152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6276 - mean_absolute_error: 0.6574\n",
      "Validation loss: 0.628\n",
      "Validation accuracy: 0.657\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_aug_1000.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_aug_100.save(\\\"models/model_standard_1000_augmented.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Evaluate the model on the validation dataset\\nval_loss, val_acc = model_aug_1000.evaluate(X_val, y_val)\\nprint(\\\"Validation loss: {:.3f}\\\".format(val_loss))\\nprint(\\\"Validation accuracy: {:.3f}\\\".format(val_acc))\\n\\n\\n# Save the model\\nmodel_aug_100.save(\\\"models/model_standard_1000_augmented.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_acc = model_aug_1000.evaluate(X_val, y_val)\n",
    "print(\"Validation loss: {:.3f}\".format(val_loss))\n",
    "print(\"Validation accuracy: {:.3f}\".format(val_acc))\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_aug_100.save(\"models/model_standard_1000_augmented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50a1b607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 480)               2400      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                30784     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,314\n",
      "Trainable params: 33,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"model_aug_1000.summary()\";\n",
       "                var nbb_formatted_code = \"model_aug_1000.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_aug_1000.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be5bee70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units_1': 480,\n",
       " 'activation_1': 'relu',\n",
       " 'units_2': 64,\n",
       " 'activation_2': 'tanh',\n",
       " 'optimizer': 'rmsprop',\n",
       " 'learning_rate': 0.01,\n",
       " 'tuner/epochs': 100,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"best_hps_aug_1000.values\";\n",
       "                var nbb_formatted_code = \"best_hps_aug_1000.values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_aug_1000.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9251f1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"model = tf.keras.Sequential()\\nmodel.add(tf.keras.layers.Dense(480, activation='relu', input_shape=(4,)))\\nmodel.add(tf.keras.layers.Dense(64, activation='tanh'))\\nmodel.add(tf.keras.layers.Dense(2))\\n\\n# Compile the model\\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\\n              loss='mean_squared_error',\\n              metrics=['mean_absolute_error'])\\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\";\n",
       "                var nbb_formatted_code = \"model = tf.keras.Sequential()\\nmodel.add(tf.keras.layers.Dense(480, activation=\\\"relu\\\", input_shape=(4,)))\\nmodel.add(tf.keras.layers.Dense(64, activation=\\\"tanh\\\"))\\nmodel.add(tf.keras.layers.Dense(2))\\n\\n# Compile the model\\nmodel.compile(\\n    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\\\"loss\\\", patience=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(480, activation='relu', input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(2))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_absolute_error'])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49c15d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2288 - mean_absolute_error: 0.3724 - val_loss: 0.1878 - val_mean_absolute_error: 0.3355\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1419 - mean_absolute_error: 0.2923 - val_loss: 0.1498 - val_mean_absolute_error: 0.2925\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1196 - mean_absolute_error: 0.2663 - val_loss: 0.1334 - val_mean_absolute_error: 0.2836\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1078 - mean_absolute_error: 0.2508 - val_loss: 0.1396 - val_mean_absolute_error: 0.2769\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0993 - mean_absolute_error: 0.2401 - val_loss: 0.2309 - val_mean_absolute_error: 0.3901\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0919 - mean_absolute_error: 0.2291 - val_loss: 0.1340 - val_mean_absolute_error: 0.2951\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0852 - mean_absolute_error: 0.2196 - val_loss: 0.0916 - val_mean_absolute_error: 0.2491\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0800 - mean_absolute_error: 0.2119 - val_loss: 0.1106 - val_mean_absolute_error: 0.2552\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0747 - mean_absolute_error: 0.2023 - val_loss: 0.2058 - val_mean_absolute_error: 0.3509\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0721 - mean_absolute_error: 0.1984 - val_loss: 0.0941 - val_mean_absolute_error: 0.2312\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0683 - mean_absolute_error: 0.1923 - val_loss: 0.0933 - val_mean_absolute_error: 0.2351\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0653 - mean_absolute_error: 0.1865 - val_loss: 0.0779 - val_mean_absolute_error: 0.2297\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.1835 - val_loss: 0.0760 - val_mean_absolute_error: 0.2191\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0601 - mean_absolute_error: 0.1783 - val_loss: 0.1335 - val_mean_absolute_error: 0.2625\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0588 - mean_absolute_error: 0.1760 - val_loss: 0.0741 - val_mean_absolute_error: 0.1981\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0571 - mean_absolute_error: 0.1735 - val_loss: 0.2428 - val_mean_absolute_error: 0.3458\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0555 - mean_absolute_error: 0.1705 - val_loss: 0.1602 - val_mean_absolute_error: 0.3069\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0538 - mean_absolute_error: 0.1690 - val_loss: 0.0785 - val_mean_absolute_error: 0.2151\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0522 - mean_absolute_error: 0.1654 - val_loss: 0.1195 - val_mean_absolute_error: 0.2600\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0512 - mean_absolute_error: 0.1635 - val_loss: 0.2071 - val_mean_absolute_error: 0.3372\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0495 - mean_absolute_error: 0.1610 - val_loss: 0.2618 - val_mean_absolute_error: 0.4090\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0485 - mean_absolute_error: 0.1582 - val_loss: 0.0475 - val_mean_absolute_error: 0.1663\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0486 - mean_absolute_error: 0.1591 - val_loss: 0.1761 - val_mean_absolute_error: 0.3157\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0463 - mean_absolute_error: 0.1550 - val_loss: 0.0883 - val_mean_absolute_error: 0.2195\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0464 - mean_absolute_error: 0.1540 - val_loss: 0.0612 - val_mean_absolute_error: 0.1894\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0456 - mean_absolute_error: 0.1537 - val_loss: 0.0931 - val_mean_absolute_error: 0.2267\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0453 - mean_absolute_error: 0.1521 - val_loss: 0.1938 - val_mean_absolute_error: 0.3196\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0446 - mean_absolute_error: 0.1502 - val_loss: 0.1484 - val_mean_absolute_error: 0.2810\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0434 - mean_absolute_error: 0.1491 - val_loss: 0.0545 - val_mean_absolute_error: 0.1773\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0430 - mean_absolute_error: 0.1480 - val_loss: 0.1302 - val_mean_absolute_error: 0.2717\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.0427 - mean_absolute_error: 0.1466 - val_loss: 0.1229 - val_mean_absolute_error: 0.2779\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0425 - mean_absolute_error: 0.1465 - val_loss: 0.1002 - val_mean_absolute_error: 0.2403\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0419 - mean_absolute_error: 0.1463 - val_loss: 0.1190 - val_mean_absolute_error: 0.2517\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0421 - mean_absolute_error: 0.1458 - val_loss: 0.1747 - val_mean_absolute_error: 0.3178\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0413 - mean_absolute_error: 0.1430 - val_loss: 0.0596 - val_mean_absolute_error: 0.1759\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0399 - mean_absolute_error: 0.1416 - val_loss: 0.0724 - val_mean_absolute_error: 0.1963\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0404 - mean_absolute_error: 0.1422 - val_loss: 0.2017 - val_mean_absolute_error: 0.3461\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0397 - mean_absolute_error: 0.1412 - val_loss: 0.1358 - val_mean_absolute_error: 0.2807\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0392 - mean_absolute_error: 0.1402 - val_loss: 0.0940 - val_mean_absolute_error: 0.2330\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0389 - mean_absolute_error: 0.1397 - val_loss: 0.1267 - val_mean_absolute_error: 0.2686\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0386 - mean_absolute_error: 0.1375 - val_loss: 0.1723 - val_mean_absolute_error: 0.3141\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0374 - mean_absolute_error: 0.1371 - val_loss: 0.2041 - val_mean_absolute_error: 0.3515\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0379 - mean_absolute_error: 0.1376 - val_loss: 0.1535 - val_mean_absolute_error: 0.2916\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0373 - mean_absolute_error: 0.1361 - val_loss: 0.0846 - val_mean_absolute_error: 0.2158\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0377 - mean_absolute_error: 0.1349 - val_loss: 0.0680 - val_mean_absolute_error: 0.2017\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0369 - mean_absolute_error: 0.1343 - val_loss: 0.1265 - val_mean_absolute_error: 0.2706\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0357 - mean_absolute_error: 0.1323 - val_loss: 0.1590 - val_mean_absolute_error: 0.2854\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0360 - mean_absolute_error: 0.1328 - val_loss: 0.2329 - val_mean_absolute_error: 0.3585\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0356 - mean_absolute_error: 0.1333 - val_loss: 0.0894 - val_mean_absolute_error: 0.2249\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0356 - mean_absolute_error: 0.1310 - val_loss: 0.1680 - val_mean_absolute_error: 0.3183\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0351 - mean_absolute_error: 0.1312 - val_loss: 0.0975 - val_mean_absolute_error: 0.2289\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0351 - mean_absolute_error: 0.1311 - val_loss: 0.2354 - val_mean_absolute_error: 0.3628\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0341 - mean_absolute_error: 0.1289 - val_loss: 0.1080 - val_mean_absolute_error: 0.2527\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0344 - mean_absolute_error: 0.1293 - val_loss: 0.2072 - val_mean_absolute_error: 0.3304\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_absolute_error: 0.1282 - val_loss: 0.0758 - val_mean_absolute_error: 0.2141\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0343 - mean_absolute_error: 0.1285 - val_loss: 0.1202 - val_mean_absolute_error: 0.2473\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0328 - mean_absolute_error: 0.1261 - val_loss: 0.1725 - val_mean_absolute_error: 0.3067\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0328 - mean_absolute_error: 0.1253 - val_loss: 0.1471 - val_mean_absolute_error: 0.2852\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0325 - mean_absolute_error: 0.1269 - val_loss: 0.1085 - val_mean_absolute_error: 0.2532\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0334 - mean_absolute_error: 0.1270 - val_loss: 0.0973 - val_mean_absolute_error: 0.2351\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0329 - mean_absolute_error: 0.1264 - val_loss: 0.1490 - val_mean_absolute_error: 0.2932\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0325 - mean_absolute_error: 0.1259 - val_loss: 0.1240 - val_mean_absolute_error: 0.2603\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0322 - mean_absolute_error: 0.1254 - val_loss: 0.1472 - val_mean_absolute_error: 0.2976\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0317 - mean_absolute_error: 0.1251 - val_loss: 0.1463 - val_mean_absolute_error: 0.2845\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0321 - mean_absolute_error: 0.1239 - val_loss: 0.1314 - val_mean_absolute_error: 0.2717\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0322 - mean_absolute_error: 0.1250 - val_loss: 0.0590 - val_mean_absolute_error: 0.1760\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0312 - mean_absolute_error: 0.1225 - val_loss: 0.1371 - val_mean_absolute_error: 0.2865\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0319 - mean_absolute_error: 0.1233 - val_loss: 0.1082 - val_mean_absolute_error: 0.2419\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_absolute_error: 0.1226 - val_loss: 0.1314 - val_mean_absolute_error: 0.2651\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0309 - mean_absolute_error: 0.1220 - val_loss: 0.0825 - val_mean_absolute_error: 0.2230\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0309 - mean_absolute_error: 0.1221 - val_loss: 0.1479 - val_mean_absolute_error: 0.2859\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0305 - mean_absolute_error: 0.1222 - val_loss: 0.1341 - val_mean_absolute_error: 0.2761\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_absolute_error: 0.1226 - val_loss: 0.0840 - val_mean_absolute_error: 0.2206\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0307 - mean_absolute_error: 0.1213 - val_loss: 0.1309 - val_mean_absolute_error: 0.2743\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_absolute_error: 0.1217 - val_loss: 0.1169 - val_mean_absolute_error: 0.2575\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0303 - mean_absolute_error: 0.1204 - val_loss: 0.1802 - val_mean_absolute_error: 0.3245\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0297 - mean_absolute_error: 0.1210 - val_loss: 0.1224 - val_mean_absolute_error: 0.2609\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0301 - mean_absolute_error: 0.1206 - val_loss: 0.1729 - val_mean_absolute_error: 0.3146\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0310 - mean_absolute_error: 0.1212 - val_loss: 0.0831 - val_mean_absolute_error: 0.2223\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0305 - mean_absolute_error: 0.1218 - val_loss: 0.1796 - val_mean_absolute_error: 0.3140\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0300 - mean_absolute_error: 0.1198 - val_loss: 0.1359 - val_mean_absolute_error: 0.2770\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0307 - mean_absolute_error: 0.1206 - val_loss: 0.2127 - val_mean_absolute_error: 0.3405\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_absolute_error: 0.1208 - val_loss: 0.1250 - val_mean_absolute_error: 0.2593\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0299 - mean_absolute_error: 0.1199 - val_loss: 0.0939 - val_mean_absolute_error: 0.2326\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0286 - mean_absolute_error: 0.1176 - val_loss: 0.1235 - val_mean_absolute_error: 0.2707\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0295 - mean_absolute_error: 0.1186 - val_loss: 0.1339 - val_mean_absolute_error: 0.2837\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0294 - mean_absolute_error: 0.1187 - val_loss: 0.1220 - val_mean_absolute_error: 0.2603\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0294 - mean_absolute_error: 0.1182 - val_loss: 0.1062 - val_mean_absolute_error: 0.2408\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0293 - mean_absolute_error: 0.1183 - val_loss: 0.1805 - val_mean_absolute_error: 0.3188\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0291 - mean_absolute_error: 0.1184 - val_loss: 0.1357 - val_mean_absolute_error: 0.2773\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0293 - mean_absolute_error: 0.1182 - val_loss: 0.1051 - val_mean_absolute_error: 0.2422\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0281 - mean_absolute_error: 0.1158 - val_loss: 0.1418 - val_mean_absolute_error: 0.2805\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0290 - mean_absolute_error: 0.1173 - val_loss: 0.1363 - val_mean_absolute_error: 0.2794\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0287 - mean_absolute_error: 0.1179 - val_loss: 0.2472 - val_mean_absolute_error: 0.3748\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0293 - mean_absolute_error: 0.1178 - val_loss: 0.2068 - val_mean_absolute_error: 0.3357\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0281 - mean_absolute_error: 0.1170 - val_loss: 0.0960 - val_mean_absolute_error: 0.2280\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0285 - mean_absolute_error: 0.1169 - val_loss: 0.1699 - val_mean_absolute_error: 0.3126\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0283 - mean_absolute_error: 0.1159 - val_loss: 0.2126 - val_mean_absolute_error: 0.3346\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0279 - mean_absolute_error: 0.1161 - val_loss: 0.1318 - val_mean_absolute_error: 0.2656\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.0290 - mean_absolute_error: 0.1178 - val_loss: 0.1470 - val_mean_absolute_error: 0.2799\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Train the model\\nhistory = model.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    validation_data=(X_val, y_val),\\n    batch_size=32,\\n    epochs=100,\\n    callbacks=[callback],\\n)\";\n",
       "                var nbb_formatted_code = \"# Train the model\\nhistory = model.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    validation_data=(X_val, y_val),\\n    batch_size=32,\\n    epochs=100,\\n    callbacks=[callback],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_augmented_1000,\n",
    "    y_train_augmented_1000,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad3bba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6276 - mean_absolute_error: 0.6574\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"val_loss, val_acc = model_aug_1000.evaluate(X_val, y_val)\";\n",
       "                var nbb_formatted_code = \"val_loss, val_acc = model_aug_1000.evaluate(X_val, y_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss, val_acc = model_aug_1000.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75b27068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 480)               2400      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                30784     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,314\n",
      "Trainable params: 33,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"model.summary()\";\n",
       "                var nbb_formatted_code = \"model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4181e9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.4530 - mean_absolute_error: 0.5490 - val_loss: 0.4338 - val_mean_absolute_error: 0.5362\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.4534 - mean_absolute_error: 0.5493 - val_loss: 0.4300 - val_mean_absolute_error: 0.5375\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4527 - mean_absolute_error: 0.5491 - val_loss: 0.4293 - val_mean_absolute_error: 0.5361\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4522 - mean_absolute_error: 0.5492 - val_loss: 0.4272 - val_mean_absolute_error: 0.5368\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4525 - mean_absolute_error: 0.5493 - val_loss: 0.4269 - val_mean_absolute_error: 0.5371\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4526 - mean_absolute_error: 0.5484 - val_loss: 0.4305 - val_mean_absolute_error: 0.5366\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4530 - mean_absolute_error: 0.5502 - val_loss: 0.4270 - val_mean_absolute_error: 0.5371\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4527 - mean_absolute_error: 0.5489 - val_loss: 0.4305 - val_mean_absolute_error: 0.5362\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4527 - mean_absolute_error: 0.5501 - val_loss: 0.4305 - val_mean_absolute_error: 0.5359\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4524 - mean_absolute_error: 0.5497 - val_loss: 0.4287 - val_mean_absolute_error: 0.5372\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4526 - mean_absolute_error: 0.5485 - val_loss: 0.4286 - val_mean_absolute_error: 0.5363\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4526 - mean_absolute_error: 0.5491 - val_loss: 0.4275 - val_mean_absolute_error: 0.5380\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4533 - mean_absolute_error: 0.5489 - val_loss: 0.4284 - val_mean_absolute_error: 0.5359\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4525 - mean_absolute_error: 0.5488 - val_loss: 0.4291 - val_mean_absolute_error: 0.5358\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4525 - mean_absolute_error: 0.5492 - val_loss: 0.4294 - val_mean_absolute_error: 0.5409\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4294 - mean_absolute_error: 0.5409\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"from tensorflow.keras.callbacks import ModelCheckpoint\\n\\n# Train the model with best hyperparameters found by the tuner\\nhistory_extra = model_100.fit(\\n    X_train_100,\\n    y_train_100,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[early_stopping, ModelCheckpoint(\\\"models/best_model.h5\\\", save_best_only=True)],\\n)\\n\\n# Evaluate the model on the test set\\nval_loss, val_acc = model_100.evaluate(X_val, y_val)\\n\\n# Save the trained model\\nmodel_100.save(\\\"models/my_model.h5\\\")\";\n",
       "                var nbb_formatted_code = \"from tensorflow.keras.callbacks import ModelCheckpoint\\n\\n# Train the model with best hyperparameters found by the tuner\\nhistory_extra = model_100.fit(\\n    X_train_100,\\n    y_train_100,\\n    epochs=100,\\n    validation_data=(X_val, y_val),\\n    callbacks=[\\n        early_stopping,\\n        ModelCheckpoint(\\\"models/best_model.h5\\\", save_best_only=True),\\n    ],\\n)\\n\\n# Evaluate the model on the test set\\nval_loss, val_acc = model_100.evaluate(X_val, y_val)\\n\\n# Save the trained model\\nmodel_100.save(\\\"models/my_model.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Train the model with best hyperparameters found by the tuner\n",
    "history_extra = model_100.fit(\n",
    "    X_train_100,\n",
    "    y_train_100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, ModelCheckpoint(\"models/best_model.h5\", save_best_only=True)],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "val_loss, val_acc = model_100.evaluate(X_val, y_val)\n",
    "\n",
    "# Save the trained model\n",
    "model_100.save(\"models/my_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dffe5602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"from tensorflow.keras.models import load_model\\n\\n# Load the saved model\\nsaved_model = load_model('models/best_model.h5')\";\n",
       "                var nbb_formatted_code = \"from tensorflow.keras.models import load_model\\n\\n# Load the saved model\\nsaved_model = load_model(\\\"models/best_model.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "saved_model = load_model('models/best_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "533fd454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,282\n",
      "Trainable params: 1,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"saved_model.summary()\";\n",
       "                var nbb_formatted_code = \"saved_model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4fe552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4531 - mean_absolute_error: 0.5488\n",
      "Test accuracy: 0.5488085150718689\n",
      "Test accuracy: 0.45308127999305725\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Evaluate the model on test data\\ntest_loss, test_accuracy = saved_model.evaluate(X_train_100, y_train_100)\\n\\n# Print the test accuracy\\nprint(\\\"Test accuracy:\\\", test_accuracy)\\n# Print the test accuracy\\nprint(\\\"Test accuracy:\\\", test_loss)\";\n",
       "                var nbb_formatted_code = \"# Evaluate the model on test data\\ntest_loss, test_accuracy = saved_model.evaluate(X_train_100, y_train_100)\\n\\n# Print the test accuracy\\nprint(\\\"Test accuracy:\\\", test_accuracy)\\n# Print the test accuracy\\nprint(\\\"Test accuracy:\\\", test_loss)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = saved_model.evaluate(X_train_100, y_train_100)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "249a7950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.45302459597587585,\n",
       "  0.45335841178894043,\n",
       "  0.45265811681747437,\n",
       "  0.45222967863082886,\n",
       "  0.45247992873191833,\n",
       "  0.4525514245033264,\n",
       "  0.4529557526111603,\n",
       "  0.45267462730407715,\n",
       "  0.45274126529693604,\n",
       "  0.45242801308631897,\n",
       "  0.4525755047798157,\n",
       "  0.45259588956832886,\n",
       "  0.4533466398715973,\n",
       "  0.45251235365867615,\n",
       "  0.4525488018989563],\n",
       " 'mean_absolute_error': [0.5490133166313171,\n",
       "  0.5492874979972839,\n",
       "  0.5491186380386353,\n",
       "  0.549187958240509,\n",
       "  0.5493232607841492,\n",
       "  0.5484479069709778,\n",
       "  0.5501682758331299,\n",
       "  0.5488965511322021,\n",
       "  0.5501302480697632,\n",
       "  0.549655556678772,\n",
       "  0.5485348701477051,\n",
       "  0.5491210222244263,\n",
       "  0.5488659143447876,\n",
       "  0.5487604737281799,\n",
       "  0.5492116808891296],\n",
       " 'val_loss': [0.43375998735427856,\n",
       "  0.42999568581581116,\n",
       "  0.4292910397052765,\n",
       "  0.4272305369377136,\n",
       "  0.4268762767314911,\n",
       "  0.430543452501297,\n",
       "  0.42696598172187805,\n",
       "  0.4304555058479309,\n",
       "  0.43053168058395386,\n",
       "  0.42871636152267456,\n",
       "  0.4286343455314636,\n",
       "  0.42745906114578247,\n",
       "  0.4283674359321594,\n",
       "  0.42907923460006714,\n",
       "  0.42941153049468994],\n",
       " 'val_mean_absolute_error': [0.5362319946289062,\n",
       "  0.5375478863716125,\n",
       "  0.5361303687095642,\n",
       "  0.5368075370788574,\n",
       "  0.537064254283905,\n",
       "  0.5366010665893555,\n",
       "  0.5371068120002747,\n",
       "  0.5362128615379333,\n",
       "  0.5358788967132568,\n",
       "  0.5372096300125122,\n",
       "  0.536271870136261,\n",
       "  0.5379956960678101,\n",
       "  0.5358992218971252,\n",
       "  0.5357885956764221,\n",
       "  0.5408858060836792]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"history_extra.history\";\n",
       "                var nbb_formatted_code = \"history_extra.history\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_extra.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a07d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
